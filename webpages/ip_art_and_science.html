<!DOCTYPE html>
<html lang="en">

<head>

    <!-- Basic Page Needs
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <meta charset="utf-8">
    <title>Daniel He's Personal Webpage: IP - Art & Science</title>
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Mobile Specific Metas
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- FONT
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

    <!-- CSS
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link rel="stylesheet" href="../css/normalize.css">
    <link rel="stylesheet" href="../css/skeleton.css">
    <style>
        body {
            background-color: rgb(228, 228, 228);
        }
    </style>

    <!-- Favicon
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link rel="icon" type="image/png" href="../asset/images/favicon.png">

</head>

<body>

    <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="container">
        <div class="row">
            <div class="twelve columns" style="background-color: #c0c0c0">
                <div style="color:rgb(0, 72, 100)">
                    <h3>Daniel He</h3>
                </div>
                <a href="index.html">Home</a>
                <a href="webpages/projects.html">Projects</a>
            </div>
            <div class="row">
                <div class="twelve columns">
                    <h1>IP: Art & Science</h1>
                </div>
            </div>

            <!-- LINUX CRASH -->

            <div class="row">
                <div class="twelve columns">
                    <h2>Linux Crash: 20190920</h2>
                    <p>
                        Our project is to express a piece of memory with light (and sound). We use Ardunio, Linux
                        Penguins, and RGB LEDs to interpret some bad memories of the Linux Penguins. In fact, many of them were
                        destroyed by some evil force last semester.
                    </p>
                </div>
            </div>
            <div class="row">
                <div class="twelve columns">
                    <video controls="controls">
                        <source src="../asset/videos/projects/linux_crash.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
            <div class="row">
                <iframe class="twelve columns" height="500" src="../asset/code/linux_crash.html">
                    <!-- <p>This is the right column</p> -->
                </iframe>
            </div>

            <div class="row">
                <div class="twelve columns">
                    <h2>Chemistry: 20190925</h2>
                    <p>
                        Our project is to express a piece of memory with light (and sound). We use Ardunio, Linux
                        Penguins, and RGB LEDs to interpret the bad memory of Linux Penguins. In fact, many of them were
                        destroyed by some evil force last semester.
                    </p>
                </div>
            </div>

            <div class="row">
                <div class="twelve columns">
                    <h2>Computer Science: RGB LED Controlling</h2> 
                    <p>In order to show the modern technics of graphics and do an introduction of representation of light using RGB values, Jerry and I designed a 
                        workshop, combining Arduino experiments and lecture together to fulfill the purpose. </p>
                    <p>Code Template (Arduino): </p>
                </div>
            </div>
            <div class="row">
                <iframe class="twelve columns" height="500" src="../asset/code/light_template.html"></iframe>
            </div>

            <div class="row">
                <div class="twelve columns">
                    <h2>Time-Based Project: Light</h2>
                    <h3>1. Thoughts Towards Driving Questions</h3>
                    <p>
                        Due to the limits of time and money, I came up with several driving questions, with their content and technical difficulties shown below.
                        <table>
                            <thead>
                                <tr>
                                    <th>Question Content</th>
                                    <th>Technical Difficulties</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>How to construct a pure optical logic gate?</td>
                                    <td>This is the first question being proposed. We already came up with a design of pure optical logic gates, but it requires
                                        polarization lens as well as semi-reflective glasses which we cannot afford.
                                    </td>
                                </tr>
                                <tr>
                                    <td>How to achieve 4D Modelling with Computer Graphics?</td>
                                    <td>This hypothesis is not achievable under the restrictions of the current time. Therefore, I will ponder through this question
                                        in my final project.
                                    </td>
                                </tr>
                                <tr>
                                    <td>How to create life using Persistent of Vision?</td>
                                    <td>This is my final driving question in this project. To build a "life", I uses an Arduino Mega, 1 accelerometer, 32 LEDs, 2 Breadboards,
                                        and a lot lot lot lot lot jumper cables.
                                    </td>
                                </tr>
                            </tbody>
                        </table>
                    </p>

                    <h3>2. Thoughts before the project</h3>
                    <p>
                        I am a computer scientist, therefore considers everything in a logical and computer-based way. I consider our world as a giant system,
                        where everything acts based on fundamental rules (for example, gravity). Similarly, I can create a different world in the field of computer science
                        with new rules and new principles. This is one of the reasons of why I like computer science: you are the god of your own world.
                    </p>
                    <p>
                        While thinking of putting art and science together, I thought of creating a "life" that follows rules, seemingly spontaneous, reacts, and tells.
                        Therefore, I designed this "life" that behaves on its own, obeying certain rules, and transfers information to us by rotating itself and using the
                         "persistent of vision" (POV) with LEDs.
                    </p>

                    <h3>3. Getting the materials</h3>
                    <p><strong>List of Materials</strong></p>
                    <ul>
                        <li>Arduino Mega x1</li>
                        <li>A bunch of Blue LEDs</li>
                        <li>2 Breadboards</li>
                        <li>Numerous Jumper Cables</li>
                        <li>Soldering Iron & Solder</li>
                        <li>Insulated Tape</li>
                        <li>1 Electronic drill</li>
                        <li>Accelerometer: MPU6050</li>
                    </ul>

                    <h3>4. Making the facility</h3>
                    <p>In order to make the facility look neater, I sawed through the breadboards and soldered wires to the back of the breadboards.</p>
                    <img src="../asset/images/ip_art_and_science_breadboard_solder.jpg" width="500">
                    <p><em>Backbone design of soldering breadboards</em></p>
                    <video controls="controls">
                        <source src="../asset/videos/projects/bread_board_solder_leds.mp4" type="video/mp4">
                    </video>
                    <p><em>"Magic": Powering up LEDs with only a breadboard</em></p>

                    <h2 id="sound">Research Project: Sound</h2>
                    <h3>Questions of Sounds</h3>
<pre>声音如何产生？
声音的音波该如何呈现？
声音如何被视觉表达？
声音能否用算法转换为颜色？
如何建模声音？
音色该如何模仿？
为什么真空不能传声？
声波和光波的本质区别？
如何接受声音？
如何量化接收到的声音？</pre>
                    
                    <h3>My Research</h3>
                    <p>After doing a brief research on sound and sound waves, I decided to go deeper in the aspect of the production and receiving of sounds. 
                        The basic results and elements of my research is shown below.
                    </p>

                    <h4>The basic properties of sound waves</h4>
                    <p>We all know that sound has three basic properties: loudness, tune, and tone. Loudness specifies the intensity of the sound, tune the acuteness,
                        and tone the style. However, this principle can be explained in a more fundamental way.
                    </p>
                    <p>We all know that sound takes the form of a wave, in the meantime being a function of time. Therefore, sound can be analyzed as mathematical wave functions.
                        For a mathematical function, the most important properties are the amplitude and the wavelength, which stands for the intensity of fluctuating
                        and the length between two crests/two troughs, respectively, as shown in the diagram below.
                    </p>
                    <img src="../asset/images/math_wave_properties.jpg">
                    <p>From the mathematic perspective, it is easy to notice that the loudness and tune correlates with the amplitude and wavelength of the soundwaves.
                        However, for the tone of the sound, it is the <em>shape</em> of the wave that matters. For instance, the diagram above is what we call a <em>sine</em>
                        wave. Another wave pattern is the square wave, as shown below. This kind of wave is the most convenient kind of wwave in buzzers, for the square wave 
                        can easily be produced by sending out electric signals to the pin of the buzzer. An experiment related to the square wave is conducted, as described
                        below.
                    </p>
                    <img src="../asset/images/square_wave_diagram.jpg">

                    <h4>Two different process of producing sound: human vocal/productions in movies</h4>
                    <p>In this part, I conducted my research in two different parts:</p>
                    <ul>
                        <li>Human Vocal</li>
                        <li>Production of sound in movies/films</li>
                    </ul>

                    <h5>Human Vocal</h5>
                    <p>The main way for humans to pronounce sound is to control his/her throat. A gut of vibrating air, sent out by the trilling throat, forms vowels
                        and consonents by the obstruction of mouth. In the language <em>Quenya</em>, the process of pronouncing the vowel is described as "<em>
                            it is easy to feel how the air streams quite unhindered though the mouth: One merely configures the tongue and lips to "shape" the desired sound
                        </em>". Consonents, respectively, are similar.
                    </p>
                    <p>Many different approaches was made based on the human vocal. For instance, the function of voice-demanding in Siri, recognizes people based on the pattern
                        of their voices. Other interesting applications include the alteration of tune using Vocaloid or other softwares based on primitive voice recordings.
                    </p>

                    <h5>Production of sound in movies/films</h5>
                    <p>When a movie is being produced, its video is recorded prior, and its sound is synthesized later. The sound of movies include the background sound and the 
                        character's voices. While the voice of roles can be recorded in a recording room easily, creating sound for background is not that easy. The most popular
                        solution to this is to mimic the sound, or make it sound even better. Below is a research about the mimicing process.
                    </p>
                    <div class="row">
                        <div class="twelve columns">
                            <video controls="controls">
                                <source src="../asset/videos/projects/piano_arduino_play.mp4" type="video/mp4">
                            </video>
                        </div>
                        <p><em>Experiment & Research: Sound in Movies</em></p>
                    </div>
                    <p>It is interesting to notice the flexibility of how our brain handle the signal it received. When a sound passes through the air, it is conveyed into
                        electric signal by the ear, and ends up at the Auditiver Cortex of the brain through neurons. While our brain is processing, it breaks the sound apart 
                        into small parts. The final result of the recognition comes out by assembling these small pieces together. This algorithm is now widely used in 
                        the recognition process of artificial intelligence.
                    </p>

                    <h4>Electronics: Producing and Receiving Sounds —— The Earphone</h4>
                    <p>The last part that I looked into is the electronic version of producing and receiving sounds. Before actually getting into the details,
                        we need two knowledge prerequisites:
                    </p>
                    <ol>
                        <li>A force is exerted to a conductor with current inside when the conductor is in a magnetic field.</li>
                        <li>If a part of a circular circut is cutting the magnetic field lines, a current is created inside the circut.</li>
                    </ol>
                    <p>Based on these basic knowledge, the <em>earphone</em> and the <em>microphone</em> is created. When the phone decided to play music, a small 
                        electric current is sent to the earphone, making the conductor inside the magnetic field vibrate. The frequency of the vibration depends on the 
                        intensity of the current, and is therefore controllable. The vibration causes the air to trill, thus the sound. The microphone works just the same
                        way. When sound is passed to the microphone, the small plate inside the microphone vibrates, causing the current in the conductor. This current
                        is then amplified and picked up by the computer/device attached, or even compressed into an audio file. Below are the images of earphones and microphones;
                        two experiments are conducted with the help of these principles.
                    </p>
                    <img src="../asset/images/earphone.jpg">
                    <img src="../asset/images/microphone.png">
                    

                    <h3>My Projects</h3>
                    <p>After researching in the production and receive of sounds, I used the open-source chip <em>Arduino</em> to experiment with sound.</p>

                    <h4>Experiment 1: Manipulating the frequency of sounds created by a passive buzzer </h4>
                    <p>A passive buzzer is a device that can make sound by receiving electric signals. In order to give off notes, we have to manipulate the frequency 
                        of the sound being produced. This is done by sending out high/low electric signals with different time intervals, causing the parts in the buzzer
                        to vibrate. This way, the buzzer produces square waves with various frequencies.
                    </p>
                    <p>In order to help other learners understand the way of modelling sound and go through the process of producing sounds, I opened up a workshop,
                        giving them the experience of using coding to generate sounds. Below is the construction image and the generalized code for the workshop.
                    </p>

                    <img src="../asset/images/passive_buzzer_line_arduino.png">
                    <div class="row">
                        <iframe class="twelve columns" height="500" src="../asset/code/sound_template.html"></iframe>
                    </div>

                    <div class="row">
                        <div class="twelve columns">
                            <video controls="controls">
                                <source src="../asset/videos/projects/piano_arduino_play.mp4" type="video/mp4">
                            </video>
                        </div>
                        <p><em>A recording of the passive buzzer music</em></p>
                    </div>
                    
                    <h4>Experiment 2: Detection of sound & alarm when loudness reaches threshold </h4>
                    <p>My another attempt is to use the sound receiver (microphone) to measure the loudness of the sound around it, which is characterized as the amplitude
                        of the sound waves, as mentioned above. When a threshold of loudness is reached, the RGB light will turn red, sending out a warning.
                        This facility can be used to measure the quietness of a working space in Moonshot.
                    </p>
                    <p>The basic properties and working principles of the sound detector is a bit different with a regular microphone as described in the research part.
                        In reality, the microphone is connected to the Arduino chip by three pins: 5V, GND, and an input pin (for example, A0). The parts of vibrating
                        stays the same, but an additional screw serves the need to alter the threshold of sound loudness. When the limit is reached, the sound detector will 
                        convey the electric current from 5V to the input pin A0.
                    </p>

                    <img src="../asset/images/sound_detector_line_arduino.png">
                    <div class="row">
                        <iframe class="twelve columns" height="500" src="../asset/code/sound_test.html"></iframe>
                    </div>
                    <div class="row">
                        <div class="twelve columns">
                            <video controls="controls">
                                <source src="../asset/videos/projects/arduino_sound_detecting_demo.mp4" type="video/mp4">
                            </video>
                        </div>
                        <p><em>A video demo of the sound detecting facility</em></p>
                    </div>

                    <h4>Experiment 3: Voicing for a movie</h4>
                    <p>Finally, I decided to voice for Aragorn, Legolas, and Boromir in the movie <em>The Lord of the Rings: The Fellowship of the Ring</em>. The video 
                        is shown below.</p>
                    <div class="row">
                        <div class="twelve columns">
                            <video controls="controls">
                                <source src="../asset/videos/projects/lotr_voicing.mp4" type="video/mp4">
                            </video>
                        </div>
                        <p><em>Daniel-voiced LotR Video</em></p>
                    </div>
                    
                    <h4>Different ways of <em>art</em></h4>
                    <ul>
                        <li>Painting</li>
                        <li>Illumination</li>
                        <li>Building</li>
                        <li>Screenshot</li>
                        <li>Suspension of objects</li>
                        <li>Wrapping & material tweaking</li>
                        <li>Captivity presentation</li>
                        <li>Posters</li>
                        <li>Lines and Weaving</li>
                        <li>3D Objects</li>
                        <li>Slicing of creatures</li>
                        <li>Ground spliting/painting</li>
                        <li>Repitition</li>
                        <li>Self-aware paints</li>
                        <li>Experience</li>
                        <li>News & Events</li>
                        <li>Clothing</li>
                        <li>Satire Comic</li>
                        <li>Computer Graphics</li>
                        <li>Abstract Information & Presentation</li>
                        <li>Letters and Natural Languages</li>
                        <li>Calligraphy</li>
                    </ul>

                    <h2 id="final">Final Project</h2>

                    <h3>Project Abstract</h3>
                    <div class="twelve columns">
                        <p>Currently, the field of computer graphics grow complete and sophisticated. One of the most unique properties of computer graphics is that it can 
                            create things <em>"unreal"</em>: from a world without gravity to a dozen self-rotating balls, from simulating a car accident to a complex blobbing shape,
                            computer graphics offers the power of creating impossible.
                        </p>
                        <p>Meanwhile, the imagination of higher spacial dimensions are thriving as ever. Visions begin to take place in fiction novels: for example, in 
                            Cixin Liu's <em>Threebody III: Death's End</em>, the spaceships from the Earth had encountered 4-Dimensional fractions in the space.
                        </p>
                        <p>Having considered these two different aspects, I decided to start a project on the modelling of 4D Objects. The desired final outcome of this
                            project will be a 4D-Modelling Software, supporting the main modelling processes of current 3D Modelling Softwares,
                            for example, viewing, intersecting, UV Mapping, illumination, and other functions (see the figure below). Of course, as a three-dimensional creature,
                            our brain cannot process a 4D Object directly; therefore, this application provides two different methods of decreasing dimensions: slicing and projection.
                        </p>
        
                        <img src="../asset/images/ip_art_and_science_3d_modelling_software_panel.png">
        
                        <p>I also want to model several interesting optical illusions in this software, for instance, the Penrose stairs (shown below). These optical illusion objects
                            theoretically exists as 4D objects. Also, a paper may be written to describe the process.
                        </p>
        
                        <img src="../asset/images/ip_penrose_stairs.jpg" width="500px">
                        <p><em>A Depiction of the Famous Penrose Stairs</em></p>
                    </div>

                    <h3>Origination of Idea</h3>
                    <div class="twelve column">
                        <h4>
                            Optical Illusion
                        </h4>
                        <p>
                            Since I was very young, I grew an interest in the world of Optical Illusion. The master of optical illusion drawings is Maurits Cornelis Escher, depicting weird spaces in all kinds of methods. Stairs are twisted into impossible angles and water flow from low places to high places. In these paintings, two of the most important elements are called the Penrose triangle and the Penrose stairs. Penrose triangle is a triangle with three ninety-degreed angles, while Penrose stairs ascend/descend infinitely.
                        </p>
                        <p>
                            In the fall of 2018, I attended a course called “if the eyes deceive you” in Moonshot. As my final project, I used Unity, Maya, and 123D Design to recreate the Penrose Stairs and the Penrose triangle. By setting my viewing direction to a specific angle, the deliberately modelled cubes and spheres overlap with each other, creating beautiful optical illusions. A screenshot of my project is shown below. On the left, the Penrose triangle rotates around the middle; on the right, the ball falls infinitely along the stairs.
                        </p>
                        <p>
                            A third piece of inspiration comes from novels and Wikipedia webpages. Currently, more and more science fiction novels include the elements of higher dimensions, even the famous ThreeBody by Liu Cixin. The fourth dimension is described repeatedly by all kinds of authors, leaving the space of imagination to their mass readers. Being one of them, I couldn’t help thinking: what on earth are higher dimensions like? How can we visualize or recreate them so that we can at least try to understand them?
                        </p>
                        <p>
                            Standing at the brink of proposing a topic, the current project burst into my mind: I shall make a 4D modelling application, having the ability to turn 4D objects into 3D by orthogonal projection.
                        </p>
                        <p>
                            And that’s the origin of my story. The start of my story.
                        </p>
                    </div>
        
                    <h3>Decreasing Dimensions</h3>
                    <p>Technically there are two main methods of decreasing dimensions: Slicing and Projection. </p>

                    <h4>Slicing</h4>
                    <p>Slicing, as its name indicates, decreases the dimensions by setting a particular coordinate to a fixed number. Here, we assume that our
                        world is on the 3D-plane (x, y, z, 0), or w = 0. Below is a video that explains the slicing of Hyperspheres, Hypercones, and Tesseracts clearly.
                    </p>
                    <div class="row">
                        <div class="twelve columns">
                            <video controls="controls">
                                <source src="../asset/videos/projects/4d_slicing.mp4" type="video/mp4">
                            </video>
                        </div>
                        <p><em>Slicing of 4D Objects</em></p>
                    </div>

                    <h4>Projection</h4>
                    <p>Another option of decreasing dimensions are making projections: from a 4D space to a 3D plane. Below is a diagram showing a rotating projected tesseract.</p>
                    <img src="../asset/images/ip-art-and-science-8-cell-orig.gif">

                    <h4>Introduction</h4>
                    <p>The process of displaying can be divided into: transformation of objects, projection of objects, clipping, illumination ray-tracing, and color determination.
                        The essence of these procedures are <em>matrix operations</em> and <em>linear algebra</em>. I will not introduce the mathematical models, but I will do a brief
                        introduction on these steps.
                    </p>

                    <p>
                        The first and most fundamental algorithm in the world of Computer Graphics is the transformation matrices. Being the absolute base, they act in all kinds of calculations, moving the object around, rotating them, and scaling them. There are three kinds of transformation matrices: TranslationMatrix, RotationMatrix, and ScaleMatrix. By multiplying the matrices on the original homogeneous coordinate representation, we get the new object swiftly.
                    </p>
                    <p>
                        The second step of viewing the object constitutes of face-detection and clipping. Because of the limited resources in both calculation powers and RAM, we choose to display and calculate as less as possible. Face-detection acts to wipe out faces that are completely unseen, while clipping algorithms clip the lines out of the projection cone.
                    </p>
                    <p>
                        After that, we come to the world of surfaces and illuminations. Algorithms of illumination is actually based on real-world physics. Computers run huge calculations called ray-tracing, tracing the rays of light emitted from the environment or from a single-point light source. Surfaces reflect the rays based on mathematical models, changing the color, strength, and direction of the light rays in the process. After the ray-tracing, the color of every pixel is determined by the ray targeted at that point in the orthographic projection.
                    </p>

                    <h4>Project Management</h4>
                    <ul>
                        <li>Math Facilities (Matrix Operations, Vector Operatinos, Color, etc.) 15%</li>
                        <li>Transformation Matrices 15%</li>
                        <li>Projection Matrices 10%</li>
                        <li>Clipping & Visible Face Detection 10%</li>
                        <li>Illumination: Phong Shading, Ray Tracing 25%</li>
                        <li>Building DataBase: Saving the points 5%</li>
                        <li>Display & User Interface 10%</li>
                        <li>Object Display 10%</li>
                    </ul>
                    <p>Current Process: Building DataBase</p>
                </div>
            </div>
        </div>

        <!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>

</html>